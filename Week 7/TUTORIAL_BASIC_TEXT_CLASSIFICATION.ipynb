{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## TUTORIAL. Machine Learning Methods for NLP -I - Text Classification\n",
        "\n",
        "In this tutorial, let's cover text-classification using machine learning methods. For this we chose the popular text classificaiton task of **Sentiment Analysis**.\n",
        "\n",
        "**This tutorial is graded**. complete the exercises and turn in under week 7.\n",
        "\n",
        "### 1. What is Sentiment Analysis\n",
        "Sentiment analysis (SA), formally known as opinion mining, is a natural language processing (NLP) task that involves determining and quantifying the emotional tone or sentiment expressed within a piece of text, typically written or spoken language. In simple terms, sentiment analysis aims to classify text into predefined categories that represent the sentiment or emotional polarity conveyed by the text. These categories are typically binary, classifying text as either *positive* or *negative*, but they can also be more fine-grained, such as *positive*, *negative*, or *neutral*.\n",
        "\n",
        "### 1.1. Dataset for SA\n",
        "There are many datasets out there for sentiment analysis from which we chose the popular  \"IMDb movie reviews dataset.\" It is a widely used dataset for sentiment analysis and consists of 2000 movie reviews from the Internet Movie Database (IMDb) website -- 1000 positive and 1000 negative. The dataset is often used to train and evaluate machine learning models for sentiment classification tasks. The IMDB movie review data is now a part of NLTK and can be accessed through **nltk.download()**.\n",
        "\n",
        "**Note:** I have already extracted and provided the training and test data in the form of CSV files.\n",
        "- `train.csv` - Contains 80% of the IMDB data to be used for training classifiers.\n",
        "\n",
        "- `test.csv` - Contains 20% of the IMDB data to be used for training classifiers.\n",
        "\n",
        "Each CSV file has two columns\n",
        "\n",
        "- **text** : containing the movie review\n",
        "- **sentiment** : containing the original sentiment -- 0 representing negaitve and 1 representing positive\n",
        "\n",
        "Let's load the data in dataframes\n"
      ],
      "metadata": {
        "id": "UJzH-5UASWgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# These two lines are needed to print variables by just mentioning them, e.g., training_data.head()\n",
        "# If we don't use this, only the last call of a variable gets printed\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "training_data = pd.read_csv(\"train.csv\")\n",
        "print (f\"Training Data: {len(training_data)} example\")\n",
        "training_data.head()\n",
        "\n",
        "test_data = pd.read_csv(\"test.csv\")\n",
        "print (f\"Test Data: {len(test_data)} example\")\n",
        "test_data.head()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "CQLf8DelXdWq",
        "outputId": "fdf0ff36-2b87-4d4f-c820-c459fccd8536"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data: 1600 example\n",
            "Test Data: 400 example\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label\n",
              "0  the verdict : spine-chilling drama from horror...      1\n",
              "1   \" the 44 caliber killer has struck again . \" ...      0\n",
              "2  in the company of men made a splash at the sun...      1\n",
              "3  in the year 2029 , captain leo davidson ( mark...      0\n",
              "4  [note that followups are directed to rec . art...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-245ebe31-682f-4622-94cc-838bff1b8e98\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the verdict : spine-chilling drama from horror...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\" the 44 caliber killer has struck again . \" ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>in the company of men made a splash at the sun...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>in the year 2029 , captain leo davidson ( mark...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[note that followups are directed to rec . art...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-245ebe31-682f-4622-94cc-838bff1b8e98')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-245ebe31-682f-4622-94cc-838bff1b8e98 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-245ebe31-682f-4622-94cc-838bff1b8e98');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a2b08bba-a2bb-4610-92a3-12f9ef1d6ab3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a2b08bba-a2bb-4610-92a3-12f9ef1d6ab3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a2b08bba-a2bb-4610-92a3-12f9ef1d6ab3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_data",
              "summary": "{\n  \"name\": \"test_data\",\n  \"rows\": 400,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 400,\n        \"samples\": [\n          \" \\\" snake eyes \\\" is the most aggravating kind of movie : the kind that shows so much potential then becomes unbelievably disappointing . \\nit's not just because this is a brian depalma film , and since he's a great director and one who's films are always greeted with at least some fanfare . \\nand it's not even because this was a film starring nicolas cage and since he gives a brauvara performance , this film is hardly worth his talents . \\nit's worse than that . \\nit's aggravating for the sole reason that its story could be so much more , could be totally intelligent , and it opens up with absolutely no subtlety that it will be handled complexly and intensely . . . then at one point in the movie makes on wrong turn that leads it to the hall of fame of half-assedness . \\nor more deservedly , the hall of fame of the eighth-assedness . \\nin certain circles , \\\" snake eyes \\\" was being advertised as a kind of modern day version of kurosawa's classic \\\" rashomon , \\\" where a crime is told from the four different ( and i mean different ) perspectives , and it looks as though it may actually be just like this with the opening , which , i might add , is superb . \\nin one very very very long steadicam shot , we meet the protagonist , crooked atlantic city detective , rick santoro ( cage ) , and follow him before a boxing match as he talks on his cell phone with his wife , interupts a pay-per-view event on tv , chases down a gambler , enters the arena all pumped up for the fight , sits down and talks with his bud , kevin dunne ( gary sinise , who's character should not be confused with that of actor kevin dunn , who's also in this ) , and watches as it happens . \\nthere's a big name in the crowd , and that's the secretary of defense , charles kirkland ( joel fabiani ) , who's sitting behind rick , and who gets shot a second after the heavyweight champion , lincoln tyler ( stan shaw ) , is knocked out . \\nthis all happens in the opening shot , and it creates so many red herrings and possibilities of what happened that it opens this scene up for close examination and total deconstruction . \\nwhat really happened , this film asks , and it sets this film up extremely well for when rick begins to question people and get different perspectives on the scene . . . and \\ndiscovers there's a very good possibility it was a conspiracy . \\nas we follow rick trying to learn of more information , we also meet a woman who was talking to kirkland before he was shot ( carla gugino ) , and who flees the scene in a panic , and tries to hide from the cops in the arena and the adjacent casino/hotel since the cops have blocked off the doors so they can get witness' takes on what happened . \\nthis is all going pretty fine and dandy , and it's extremely interesting to watch . . . then \\nit takes one wrong step . \\nwe follow the wrong character , and we learn of the answer to the mystery too early on , and way before rick can find it out . \\nbut that's not the worst part of it : it's that it's the one person you didn't think it would be because he was too obviously supposed to be the red herring , the one you didn't think did it because it would be stupid and cliched of that person to be behind it . \\nit only gets worse : the film turns into a chase film about half way through the film , and since we already know what happened , we can't rely on rick's investigation to be all that interesting . \\nit's as if the film ran out of the guts to be really complex and original about a third of the way in , and decided to just fall back on an easy way out , and that just happens to mean that it has to become less and less credible . \\nevents become more and more proposterous , and by the end , the film has decided to rely on the worst offender in mysteries like this : the deux ex machina . \\nthat's where some outside intereference brings the film to a sudden conclusion and makes everything okay . \\nthis time , it's a hurricane , an out-of-control police car , and a big round ball that adorned the arena . \\nwhat went wrong ? \\ndepalma and the screenwriter , david koepp , are extremely credible people in their respective fields , and have been known for bringing life and complexity to mysteries such as this . \\ndepalma , who idolizes hitchcock to death , has done many a film like this , such as his masterpiece , \\\" blow out , \\\" where a movie soundman uses movie elements to uncover a conspiracy piece by piece . \\nbut granted , depalma at least makes it intriguing to watch , what with his over-the-top shot set-ups , notably the beginning and a sequence where the camera pans over top of a bunch of rooms in the hotel , forgetting anything about boundaries . \\nat least his direction makes up partly for it . \\nthen there's koepp , who showed such great ability at making a character's flaws come to life like he did in depalma's earlier \\\" carlito's way , \\\" a film that dove right into the life and past of its character and examined him extremely well . \\nhe can write a flawed character , but his rick santoro seems to be just a half-assed effort . \\nhe's flawed , and we can see redemption if the story wasn't so formulaic . \\na scene towards the end where he has to make a fatal decision is cheapened by the fact that his answer has no emotional buildup . \\nhe may as well have said the opposite of what he says ; it would have at least gone with what the character was like . \\nthis is the most disappointing kind of film because it promises intelligence and complexity , because it promises disection of a flawed character and perhaps even redemption , then pulls the rug from under us just as we were about to be convinced it would be able to go all the way . \\nas i was watching the first half hour , i couldn't wait to see how the mystery would be unearthed , how many different perspectives he'd be given , and perhaps he'd have to make a choice between who's he has to believe . \\nnow there's a film . \\nunfortunately , the film has two major deux ex machinas : one in the disasterous ending ; the other , about a half hour in when the film goes into autopilot and becomes a stale and recycled piece of crap we've seen all too much before , but never from someone like depalma . \\n\",\n          \"there are some works of art that are almost impossible to review , not because of their own complexity , but because of their legendary status which prevents the reviewer to say anything original . \\none of such masterpieces is casablanca , probably not the best film in the history of the seventh art , but definitely the most popular one . \\nits popularity can be measured not in a multitude of more or less disguised remakes that were made in more than half a century since its premiere , but also in countless tributes and references that movie makers use in their works to this day . \\ncasablanca is also a movie that has the very rare virtue of both being praised by the critics and loved by general audience . \\none of the things that makes this film even more unique was the fact that it was doomed to fail , at least judging by conventional movie-making wisdom of its time . \\nit was based on a broadway play so mediocre that it hadn't been produced on stage ; screenplay by three writers - julius g . epstein , philip j . epstein and howard koch - was beeing written as shooting went along ; the main actors were producers' second choice , and , finally , man behind camera , michael curtiz was considered to be capable , but not great director . \\nhowever , the movie was commercially successful and earned three \\\" oscars \\\" , including the one for the best film . \\nuntil this very day , it is considered to be the best example of hollywood film- making in its own golden age . \\nthe plot of the movie was heavily influenced by the needs of ww2 propaganda , yet it also used rather complicated and now almost forgotten political circumstances of that global conflict in order to make intriguing story . \\nin december 1941 , casablanca , exotic port on the atlantic coast of north africa is controlled by officially neutral , yet nazi-collaborating french vichy government . \\nthousands of refugees from war-torn europe are stuck there on the way to lisbon and safety of america , and ready to pay any price for precious exit visas . \\nmany shady characters thrive on their misery , including the corrupt police chief , captain renault ( rains ) . \\nhis best friend is rick blaine ( bogart ) , who used to be idealistic anti-fascist , and now owns popular night club in casablanca and lives by his own cynical philosophy of \\\" sticking his neck for nobody \\\" . \\nhowever , everything changes when he gets in possession of two precious extra visas . \\nthis event coincides with the arrival of two new refugees to casablanca . \\none of them is victor laszlo ( henreid ) , czech resistance leader who escaped three times from nazi concentration camps and became the legend of enslaved europe . \\nhe is accompanied by his beautiful wife ilsa lund ( bergman ) , with whom rick had a stormy affair in the eve of nazi occupation of paris . \\nthe couple needs visas , especially because of the gestapo major strasser ( veidt ) being on their trail . \\nrick is now forced to choose between love , wounded pride , self-preserving interest and his own hatred of fascism . \\nthe casting for this movie seems influenced by divine inspiration - humphrey bogart , most legendary actor in the history of cinema , is one of the rare character actors who elevated his persona to the star status . \\nbogart's portrayal of rick as complicated man , torn between idealistic past and bitter present , was so perfect , that his icon would forever be connected with that character . \\nanother icon in his company is ingrid bergman , great actress of old hollywood , here in her artistic and visual prime . \\nthe cinematic coupling of bogart and bergman became one of the main symbols of that era of filmmaking - some happier times when the romance on the screen didn't look childish nor trite like in some more contemporary works . \\nfor many people , casablanca is probably the best romantic film ever made . \\nbut the reason for that isn't the romance itself - it's the realistic story of people forced to make tough , and often wrong choices in their life . \\nthe casting of casablanca was right on target not just in a case of main leads . \\nthe supporting actors also did a marvellous job . \\nsidney longstreet and peter lorre were here mainly to give a mystic flavour spotted in a previous bogart classic - john huston's maltese falcon ; yet both of them managed to portray colourful and original characters . \\nanother shining example of good casting is now almost forgotten paul henreid as the weakest part of love triangle ; character of victor laszlo has believable charisma and looks like a somebody who could inspire millions of people to rise against nazi tiranny . \\nunfortunately , the charisma that burdened laszlo , leaves little place for difficult choice , making his character forever overshadowed by rick/ilsa coupling . \\nhowever , rick and ilsa actually have a serious competiton for most memorable character in casablanca . \\ncaptain renault , brilliantly portrayed by claude rains in a role of a lifetime , was embodiment of perfect , almost unmatched balance between ethical corruption and physical charm . \\ndespite being the undoubtful villain in almost entire movie , rains managed to make renault sympathetic character , and his final conversion to the side of good , symbolized in not so subtle gesture at the end of movie looked unnecessary . \\nrains also gave another dimension to the movie , making it even more ambiguous ; people who like to analyse movies to death discovered signs of homosexuality in renault's relationship towards rick , and rick's final words leave room for even more outrageous speculations . \\ntogether with well-drawn characters and exciting story , the movie was good in creating his own atmosphere . \\nprofessional nitpickers would probably have a field day in discovering numerous historical and geographical inaccuracies , but casablanca is still a shining example of hollywood ww2 movie that is beliavable , if not realistic . \\nany way , even if we don't see it as a historical document , casablanca is movie that can be source of entertainment as well as infinite inspiration . \\n\",\n          \"all right , all right , we get the point : despite all similarities to the best-selling story , speechless is * not * based on the romance between 1992 presidential campaign rivals james carville and mary matalin . \\nin fact , the script was in development well before 1992 . \\nstill , the comparisons are inevitable , until one realizes a critical difference . \\nno , it's not that the speechless twosome are speech writers , not campaign managers ; it's that carville and matalin's story is actually interesting . \\nspeechless is a limp , poorly structured would-be romantic comedy . \\nspeechless is set during a new mexico senatorial campaign , where kevin vallick ( michael keaton ) and julia mann ( geena davis ) meet and get romantic one night when neither one can sleep . \\nwhat neither one realizes is that they are on opposite sides of the campaign : kevin is a sit-com writer brought in to punch up the republican candidate's speeches , while julia is the chief speech writer for the democratic candidate . \\nat first each one believes that the other has an ulterior motive for the relationship , but eventually they let down their guard and become closer . \\nbut there are plent of obstacles in the way , including julia's stud-reporter fiance ( christopher reeve ) and a series of stunts which continue to prove that all's fair in love and politics . \\nthe standard formula for a movie like speechless would have the two principles starting out as antagonists and realizing only at the end that they're crazy about each other . \\nscreenwriter robert king completely subverts expectations by throwing kevin and julia into each other's arms in the first fifteen minutes , then developing the antagonism . \\nit's a noble attempt to shake things up , but unfortunately it just doesn't work . \\npart of the fun of watching sparring in a romantic comedy comes from recognizing the chemistry even before the characters do , but in speechless they already know they're attracted to each other , and we're left with waiting for the campaign to end so they'll admit that they love each other already . \\nthere is such a herky-jerky feel to the constant bickering and making up that even king's sharp dialogue can't prevent speechless from becoming repetitive after about half an hour . \\ninconsistency is also the defining characteristic of the performances of geena davis and michael keaton , and with those performances most of their scenes together . \\nthe problems begin with their initial courtship , which does virtually nothing to establish julia's character and merely establishes that kevin is a wise-ass . \\ndavis is radiantly beautiful , and keaton is generally entertaining , but these characters are so plastic that nothing that happens to them seems to matter one bit . \\nin a couple of scenes , like a quiet moment sitting at a fountain , they actually achieve some measure of connection . \\nfor the most part , however , they're just actors spouting lines . \\nyou keep waiting for a little spark , and it never happens . \\nperhaps most disappointing is that king and director ron underwood completely waste their premise by removing all the punch from speechless's politics . \\nthe setting seems perfect for a high- energy battle of the sexes with partisanship thrown into the mix , but that's never the tone that underwood is going for . \\nhe wants a warm , fuzzy romance compatible with marc shaiman's flute-and-wind musical score , and the campaign which should have defined the conflict between kevin and julia fades into the background . \\nit might as well have been a story about rival grocers , and every single character is about as uninspired as he or she could possibly be . \\ni was about the only reviewer in the civilized world who seemed to enjoy robert king's previous screenplay , the dana carvey flop clean slate , so i had some hopes for speechless . \\nbut while there is wit in the words , this is a script which was probably much better on paper . \\non screen , it's still paper thin . \\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Instantiate a bunch Machine Learning based Classifiers\n",
        "\n",
        "These classifiers work on a wide range of tasks and datasets (and not just textual data) as long as the datasets are featurized and labels are encoded into numbers.\n",
        "\n",
        "We will instantiate the following classifiers:\n",
        "\n",
        "1. Logistic Regression\n",
        "2. Support Vector Classifier\n",
        "3. Feed Forward Neural Network\n",
        "\n"
      ],
      "metadata": {
        "id": "Dr1uEerkcmQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 1. Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "## 2. Support Vector Machine\n",
        "from sklearn.svm import SVC\n",
        "## 3. Feed forward neural network or multi-layered perceptron\n",
        "from sklearn.neural_network import MLPClassifier"
      ],
      "metadata": {
        "id": "xJLItAPedJ1Y"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also write a generic function that can be reused for any classifier as long as we are using them from scikit-learn package"
      ],
      "metadata": {
        "id": "mRg9ZBiAdo7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate_classifier(classifier, X_train, y_actual, X_test, y_test_actual):\n",
        "  classifier.fit(X_train, y_actual)\n",
        "  y_pred = classifier.predict(X_test)\n",
        "  accuracy = accuracy_score(y_test_actual, y_pred)\n",
        "  return accuracy\n"
      ],
      "metadata": {
        "id": "VGU5rZ8PdxLl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Using Unigram / Bag of Words Features for classification\n",
        "\n",
        "Unigram (Bag of Words) Vectorization converts text data into a numerical representation by counting the presence-absence / frequency of individual words (unigrams) in a document, creating a sparse vector where each dimension corresponds to a unique word in the corpus. This technique disregards word order and focuses solely on word presence, making it a basic but efficient method for text classification.\n",
        "\n"
      ],
      "metadata": {
        "id": "Fu00c3mRYugU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# compute \"goodness\" of classification through accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Extract text and labels\n",
        "X_train = training_data['text']\n",
        "y_train = training_data['label']\n",
        "X_test = test_data['text']\n",
        "y_test = test_data['label']\n",
        "\n",
        "# Create a CountVectorizer for unigrams (bag of words)\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "m5MFdKCYYt_J"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and test Logistic Regression.  "
      ],
      "metadata": {
        "id": "aA0MJYV-ehBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = LogisticRegression(max_iter=1000)\n",
        "accuracy = train_and_evaluate_classifier(classifier, X_train_vec, y_train, X_test_vec, y_test)\n",
        "print (f\"Accuracy of Logistic Regression = {accuracy*100}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ki1qk3a5eeH3",
        "outputId": "8b243d33-8afe-47bb-b020-d1e7057da051"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Logistic Regression = 82.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and test SVM"
      ],
      "metadata": {
        "id": "iRr0FfW8fFz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = SVC(kernel=\"linear\")\n",
        "accuracy = train_and_evaluate_classifier(classifier, X_train_vec, y_train, X_test_vec, y_test)\n",
        "print (f\"Accuracy of Support Vector Classificaiton = {accuracy*100}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_GYQUiKe3J-",
        "outputId": "91c1a95f-6586-40c4-8a60-b73786b38efb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Support Vector Classificaiton = 81.75%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and test Feed Forward Network"
      ],
      "metadata": {
        "id": "80RyNm53fP7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = MLPClassifier(random_state=1, max_iter=300)\n",
        "accuracy = train_and_evaluate_classifier(classifier, X_train_vec, y_train, X_test_vec, y_test)\n",
        "print (f\"Accuracy of Support Vector Classificaiton = {accuracy*100}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3o0E3SxfWQF",
        "outputId": "294ddf33-d1db-4242-da90-79ec9a706c17"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Support Vector Classificaiton = 85.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Using Linguistic Features alongside unigram features\n",
        "\n",
        "Adding Part-of-Speech (POS) feature extraction to the Count Vectorizer can enhance sentiment analysis by considering the grammatical structure and syntactic information in text. POS tags provide valuable insights into the role of words in a sentence, allowing the model to capture nuances that simple word counts may miss.\n",
        "\n",
        "**Example:** Consider the sentence \"The movie was not good.\" In this case, POS tagging can help distinguish between the negation \"not\" and the sentiment-carrying word \"good.\" The Count Vectorizer alone might treat \"not\" and \"good\" as two separate unigrams without capturing their relationship. By appending POS tags, you can represent the sentence as follows: \"DT NN VB RB JJ.\" Here, DT represents determiner, NN is a noun, VB is a verb, RB is an adverb, and JJ is an adjective. This added information can help the sentiment analysis model better understand the sentence's structure and sentiment orientation.\n",
        "\n",
        "We extract POS tags from each review using one the techniques we discussed in our previous practicum. Define POS unigrams (count of each POS tag) as a feature and concatenate them with the unigram features."
      ],
      "metadata": {
        "id": "EA_TfLSphCkx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from textblob import TextBlob\n",
        "from nltk import word_tokenize, pos_tag\n",
        "import nltk\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Define a function to extract POS tags from text\n",
        "def tokenize_and_get_pos_tags(text):\n",
        "    tokens = text.split()\n",
        "    pos_tags = pos_tag(tokens)\n",
        "    return ' '.join([tag for word, tag in pos_tags])\n",
        "\n",
        "# Create a CountVectorizer for text and a CountVectorizer for POS tags\n",
        "text_vectorizer = CountVectorizer()\n",
        "pos_vectorizer = CountVectorizer()\n",
        "\n",
        "X_train_text_vec = text_vectorizer.fit_transform(X_train)\n",
        "X_test_text_vec = text_vectorizer.transform(X_test)\n",
        "\n",
        "X_train_pos_vec = pos_vectorizer.fit_transform(X_train.apply(tokenize_and_get_pos_tags))\n",
        "X_test_pos_vec = pos_vectorizer.transform(X_test.apply(tokenize_and_get_pos_tags))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTi2zIZZhBgH",
        "outputId": "0cf143d9-ac35-4069-bd65-ac787cab3338"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate the two feature sets\n",
        "import scipy.sparse as sp\n",
        "X_train_combined = sp.hstack([X_train_text_vec, X_train_pos_vec])\n",
        "X_test_combined = sp.hstack([X_test_text_vec, X_test_pos_vec])\n",
        "\n",
        "# Train a classifier\n",
        "classifier = LogisticRegression(max_iter=10000)\n",
        "\n",
        "accuracy = train_and_evaluate_classifier(classifier, X_train_combined, y_train, X_test_combined, y_test)\n",
        "print(f\"Accuracy with POS Features and Count Vectorizer: {accuracy*100}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whQ2qRcXDTdl",
        "outputId": "dc96f168-028c-4de1-94f5-625a009ee61b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with POS Features and Count Vectorizer: 82.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Using word-vectors such as Glove as features for classificaiton\n",
        "\n",
        "**Motivation:** Implementing Glove (Global Vectors for Word Representation) vector averaging as a feature can capture semantic relationships between words and improve the sentiment analysis model's understanding of text. Glove vectors encode word meanings in dense vector representations, allowing the model to capture subtle nuances in language, such as word similarities and context.\n",
        "\n",
        "Following practicum II, we can process the data and extract the average embedding vectors for each review. This vector will serve as our feature.\n",
        "\n",
        "First we download and prepare Glove vectors for usage:\n",
        "\n"
      ],
      "metadata": {
        "id": "HFn3tq1rjjgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this is a one time download\n",
        "!wget -c http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip\n",
        "\n",
        "# do some necessary conversions\n",
        "!python -m gensim.scripts.glove2word2vec --input  glove.6B.50d.txt --output glove.6B.50d.vec\n",
        "!python -m gensim.scripts.glove2word2vec --input  glove.6B.200d.txt --output glove.6B.200d.vec\n",
        "!rm glove*.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUHU394UkNPo",
        "outputId": "20afc57b-97ab-4806-a615-901087e39336"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-29 04:16:57--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2024-02-29 04:16:57--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2024-02-29 04:16:57--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.02MB/s    in 2m 39s  \n",
            "\n",
            "2024-02-29 04:19:36 (5.18 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n",
            "2024-02-29 04:20:15,925 - glove2word2vec - INFO - running /usr/local/lib/python3.10/dist-packages/gensim/scripts/glove2word2vec.py --input glove.6B.50d.txt --output glove.6B.50d.vec\n",
            "/usr/local/lib/python3.10/dist-packages/gensim/scripts/glove2word2vec.py:125: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
            "  num_lines, num_dims = glove2word2vec(args.input, args.output)\n",
            "2024-02-29 04:20:15,926 - keyedvectors - INFO - loading projection weights from glove.6B.50d.txt\n",
            "2024-02-29 04:20:38,489 - utils - INFO - KeyedVectors lifecycle event {'msg': 'loaded (400000, 50) matrix of type float32 from glove.6B.50d.txt', 'binary': False, 'encoding': 'utf8', 'datetime': '2024-02-29T04:20:38.487691', 'gensim': '4.3.2', 'python': '3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]', 'platform': 'Linux-6.1.58+-x86_64-with-glibc2.35', 'event': 'load_word2vec_format'}\n",
            "2024-02-29 04:20:38,489 - glove2word2vec - INFO - converting 400000 vectors from glove.6B.50d.txt to glove.6B.50d.vec\n",
            "2024-02-29 04:20:38,825 - keyedvectors - INFO - storing 400000x50 projection weights into glove.6B.50d.vec\n",
            "2024-02-29 04:20:51,918 - glove2word2vec - INFO - Converted model with 400000 vectors and 50 dimensions\n",
            "2024-02-29 04:20:53,563 - glove2word2vec - INFO - running /usr/local/lib/python3.10/dist-packages/gensim/scripts/glove2word2vec.py --input glove.6B.200d.txt --output glove.6B.200d.vec\n",
            "/usr/local/lib/python3.10/dist-packages/gensim/scripts/glove2word2vec.py:125: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
            "  num_lines, num_dims = glove2word2vec(args.input, args.output)\n",
            "2024-02-29 04:20:53,564 - keyedvectors - INFO - loading projection weights from glove.6B.200d.txt\n",
            "2024-02-29 04:22:03,031 - utils - INFO - KeyedVectors lifecycle event {'msg': 'loaded (400000, 200) matrix of type float32 from glove.6B.200d.txt', 'binary': False, 'encoding': 'utf8', 'datetime': '2024-02-29T04:22:03.029393', 'gensim': '4.3.2', 'python': '3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]', 'platform': 'Linux-6.1.58+-x86_64-with-glibc2.35', 'event': 'load_word2vec_format'}\n",
            "2024-02-29 04:22:03,031 - glove2word2vec - INFO - converting 400000 vectors from glove.6B.200d.txt to glove.6B.200d.vec\n",
            "2024-02-29 04:22:03,367 - keyedvectors - INFO - storing 400000x200 projection weights into glove.6B.200d.vec\n",
            "2024-02-29 04:23:01,078 - glove2word2vec - INFO - Converted model with 400000 vectors and 200 dimensions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# Load pre-trained GloVe embeddings\n",
        "word_vectors = KeyedVectors.load_word2vec_format('glove.6B.200d.vec', binary=False)\n",
        "\n",
        "# Define a function to calculate the average GloVe vector for a text\n",
        "def get_average_glove_vector(text):\n",
        "    vectors = [word_vectors[word] for word in text.split() if word in word_vectors]\n",
        "    if vectors:\n",
        "        return np.mean(vectors, axis=0)\n",
        "    else:\n",
        "        return np.zeros(word_vectors.vector_size)\n",
        "\n",
        "# Apply the function to the dataset\n",
        "X_train_glove = [get_average_glove_vector(text) for text in X_train]\n",
        "X_test_glove = [get_average_glove_vector(text) for text in X_test]\n",
        "\n",
        "# Train a classifier (e.g., Logistic Regression)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(max_iter=1000)\n",
        "classifier.fit(X_train_glove, y_train)\n",
        "\n",
        "# Evaluate the classifier\n",
        "y_pred = classifier.predict(X_test_glove)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy with Glove Vector Averaging:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "htWu3LL-jiXo",
        "outputId": "0789c009-d993-4578-9b88-a46e26b312e8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=1000)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with Glove Vector Averaging: 0.7575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise:\n",
        "\n",
        "Now let's do the following.\n",
        "\n",
        "1. Repeat Section 3 with TfIdfVectorizer.\n",
        "2. Try to train and evaluate SVC and MLP classifiers using GloVE features following Section 5. Write down your observations."
      ],
      "metadata": {
        "id": "IpwEnqI4ko7R"
      }
    }
  ]
}