{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Wg4-r1-u7uO"
      },
      "source": [
        "# Assignment 3: Hashtag based Tweet search\n",
        "\n",
        "We will extend Assignment 2 and work on building a vector based search for hashtag based search of tweets.\n",
        "\n",
        "Overview:\n",
        "Welcome to TweetMiner, the leading organization in Twitter data analysis! As an NLP scientist in our team, you're entrusted with the task of extracting the most relevant tweets based on input hashtags. For instance, if the hashtag is \"#abortion,\" we expect you to extract the top N (let's say N=10) tweets that truly discuss the topic of \"abortion.\" Similarly, for a hashtag like \"#politicaladvertising,\" your algorithm should identify and extract the top N (again, let's use N=10) tweets about \"political advertising\".\n",
        "For this assignment your tasks are the following:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWyn0NixzDUo"
      },
      "source": [
        "## Task 1: Use CountVectorizer (binary = true) vectorization technique and perform search\n",
        "\n",
        "### Processing Tweets:\n",
        "\n",
        "1. Pre-process tweets using applicable pre-processing techniques.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEDcivGEu5bQ",
        "outputId": "e121353c-2efc-42e1-d6e3-0645f595e8f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File Exists, skipping\n"
          ]
        }
      ],
      "source": [
        "import os.path\n",
        "if not os.path.isfile(\"preprocessed_tweets.txt\"):\n",
        "\n",
        "  # first load file! same as Assignment 2\n",
        "  with open(\"australian_election_2019_tweets.txt\") as f:\n",
        "      list_tweets = f.read().splitlines()\n",
        "\n",
        "  # pre-processing from Lab 4\n",
        "  import spacy\n",
        "  from nltk.corpus import stopwords\n",
        "  import nltk\n",
        "  nltk.download('stopwords')\n",
        "\n",
        "  # get a list of stopwords from NLTK\n",
        "  stops = set(stopwords.words('english'))\n",
        "\n",
        "  # Load SpaCy English language model\n",
        "  # this is a pipeline capable of applying morphological, lexical and syntax analysis on text\n",
        "\n",
        "  nlp_pipeline = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "  def pre_process_a_single_sentence(sentence: str):\n",
        "    # Lower case text\n",
        "    sentence = sentence.lower()\n",
        "\n",
        "    processed_sentence = []\n",
        "\n",
        "    # Tokenize, and lemmatize the text\n",
        "    doc = nlp_pipeline(sentence)\n",
        "\n",
        "    for token in doc:\n",
        "      # here token is an object that contains various information about each token\n",
        "      # information such as lemma, pos, parse labels are available\n",
        "      # we will check here if tokens are present in stopwords; if not, we will retain their lemma\n",
        "      if token not in stops:\n",
        "        lemmatized_token = token.lemma_\n",
        "        processed_sentence.append(lemmatized_token)\n",
        "    processed_sentence = \" \".join (processed_sentence)\n",
        "    return processed_sentence\n",
        "\n",
        "  # remove duplicates first\n",
        "  l_t = list(set(list_tweets))\n",
        "\n",
        "  # we use regex for removing URLs, non-english text\n",
        "  import re\n",
        "  # credit to https://www.geeksforgeeks.org/remove-urls-from-string-in-python/\n",
        "  def remove_non_english(text):\n",
        "      # Define a regex pattern to find\n",
        "      pattern = re.compile(r\"https?://\\S+|(?<=\\s)[@#]|^[@#]|[^a-zA-Z0-9\\s]\")\n",
        "\n",
        "      # Use the sub() method to replace\n",
        "      text_without_noneg = pattern.sub(\"\", text)\n",
        "\n",
        "      return text_without_noneg\n",
        "\n",
        "  ltrdru = []\n",
        "\n",
        "  for line in l_t:\n",
        "    ltrdru.append(remove_non_english(line))\n",
        "\n",
        "  # preprocess text actual\n",
        "  prepro_tweets = [pre_process_a_single_sentence(sentence) for sentence in ltrdru]\n",
        "\n",
        "\n",
        "  # save lines\n",
        "  with open('preprocessed_tweets.txt', 'w') as f:\n",
        "      for line in prepro_tweets:\n",
        "          f.write('%s\\n' %line)\n",
        "\n",
        "else:\n",
        "  print(\"File Exists, skipping\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I am skipping if I have the file saved because it takes 20 MINUTES to pre-process the file. But now I can simply load it to save time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "opened\n"
          ]
        }
      ],
      "source": [
        "prepro_tweets = []\n",
        "with open(\"preprocessed_tweets.txt\") as f:\n",
        "    for line in f.readlines():\n",
        "        # see if there is a loose blank line and skip it if so\n",
        "        if (len(line.strip()) == 0):\n",
        "            continue\n",
        "        if line:\n",
        "            prepro_tweets.append(line.strip())\n",
        "print(\"opened\")\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-JPpE0AzNBS"
      },
      "source": [
        "2. Vectorize pre-processed tweets with CountVectorizer (binary = true) . This will create sparse vectors of tweets based on its vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['10' '100' '10newsfirst' '10yourvote' '11' '12' '13' '14' '15' '15bn']\n"
          ]
        }
      ],
      "source": [
        "# also taken from lab 4\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# Define the N for N-grams\n",
        "N = 1\n",
        "# Initialize the CountVectorizer with N-gram range\n",
        "vectorizer = CountVectorizer(ngram_range=(N, N), lowercase = False, binary = True, max_features = 3000) # very low for now. I can't have it be too high\n",
        "\n",
        "# Fit and transform the corpus\n",
        "vectorizer.fit(prepro_tweets)\n",
        "\n",
        "# Check a few items in the vocabulary\n",
        "vocab = vectorizer.get_feature_names_out()\n",
        "\n",
        "# sanity check: check the list of vocabulary\n",
        "print(vocab[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transformed Tweets [array([0, 0, 0, ..., 0, 0, 0]), array([0, 0, 0, ..., 0, 0, 0]), array([0, 0, 0, ..., 0, 0, 0]), array([0, 0, 0, ..., 0, 0, 0]), array([0, 0, 0, ..., 0, 0, 0])]\n"
          ]
        }
      ],
      "source": [
        "# making a transformation of each tweet (very memory intensive and a complete space hog)\n",
        "tweet_vectors = []\n",
        "\n",
        "#We are going to process only 1000 though\n",
        "prepro_tweets = prepro_tweets[:1000]\n",
        "for sentence in prepro_tweets:\n",
        "  transformed_vector = vectorizer.transform([sentence])\n",
        "  tweet_vectors.append(transformed_vector.toarray()[0])\n",
        "\n",
        "print (\"Transformed Tweets\", tweet_vectors[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I am processing only 1000 tweets at this time though. Why? Because if I do more then my computer will crash. I've tried 30 different things and none of them work so... I will verify with 1000, and if I get a computer with more RAM in the future then I will re-run with the full dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Processing hashtags and conduct search:\n",
        "\n",
        "1. Manually define a list of 10 hashtags, initiating each with the \"#\" symbol. Ensure the list consists of 5 single-word hashtags and 5 multiword hashtags. For multiword hashtags, capitalize the first letter of each word (e.g., #PoliticalAdvertising). \n",
        "\n",
        "Hashtags used: '#RenewableEnergy', '#TaxLaws', '#ParliamentaryMajority', '#coalition', '#Labor' '#Liberal', '#Auspol', '#DemocracySausage', '#ausvotes', and '#AusVotes22'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# list of 10 hashtags\n",
        "hashtags = ['#RenewableEnergy', '#TaxLaws', '#ParliamentaryMajority', '#Coalition', '#Labor', '#Liberal', '#Auspol', '#DemocracySausage', '#Ausvotes', '#AusVotes22']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Remove the \"#\" symbol from all hashtags. If the hashtag is multiword, split it into individual words using regular expressions. Refer to the code snippet available at https://stackoverflow.com/questions/68448243/efficient-way-to-split-multi-word-hashtag-in-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Renewable Energy\n",
            "Tax Laws\n",
            "Parliamentary Majority\n",
            "Coalition\n",
            "Labor\n",
            "Liberal\n",
            "Auspol\n",
            "Democracy Sausage\n",
            "Ausvotes\n",
            "Aus Votes22\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "x = 0\n",
        "for tag in hashtags:\n",
        "    hashtags[x] = re.sub(r'#(\\w*[A-Z]\\w*)', \n",
        "                         lambda m: ' '.join(re.findall('[A-Z][^A-Z]*', m.group())), tag)\n",
        "    print(hashtags[x])\n",
        "    x += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. For each hashtag,\n",
        "\n",
        "a. Vectorize the hashtags USING THE SAME Vectorizer that you built under \"Processing Tweets\". Let's call it \"queryVector\"\n",
        "\n",
        "b. Compute the pairwise similarity between the \"queryVector\" and  each tweet vector using inverse of Euclidean Distance (you can copy the implementation from ALTERNATIVE_Lab4 notebook).  \n",
        "\n",
        "c. Rank tweets based on the similarity score in ascending order. Print the top 10 most similar tweets. \n",
        "\n",
        "d. Repeat for each hashtag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Query: Renewable Energy\n",
            "Document: 27 auspol, Score: 1.0\n",
            "Document: 71 ausvote, Score: 1.0\n",
            "Document: 90 ausvote usefulidiot, Score: 1.0\n",
            "Document: 100 auspol, Score: 1.0\n",
            "Document: 135 ausvote, Score: 1.0\n",
            "Document: 151 very engaging, Score: 1.0\n",
            "Document: 170 ausvote   barrel   jaidynlstephenson, Score: 1.0\n",
            "Document: 190 alp                 180, Score: 1.0\n",
            "Document: 194 uap 1359, Score: 1.0\n",
            "Document: 204 ausvote   electionresult, Score: 1.0\n",
            "\n",
            "Query: Tax Laws\n",
            "Document: 27 auspol, Score: 1.0\n",
            "Document: 71 ausvote, Score: 1.0\n",
            "Document: 90 ausvote usefulidiot, Score: 1.0\n",
            "Document: 100 auspol, Score: 1.0\n",
            "Document: 135 ausvote, Score: 1.0\n",
            "Document: 151 very engaging, Score: 1.0\n",
            "Document: 170 ausvote   barrel   jaidynlstephenson, Score: 1.0\n",
            "Document: 190 alp                 180, Score: 1.0\n",
            "Document: 194 uap 1359, Score: 1.0\n",
            "Document: 204 ausvote   electionresult, Score: 1.0\n",
            "\n",
            "Query: Parliamentary Majority\n",
            "Document: 27 auspol, Score: 1.0\n",
            "Document: 71 ausvote, Score: 1.0\n",
            "Document: 90 ausvote usefulidiot, Score: 1.0\n",
            "Document: 100 auspol, Score: 1.0\n",
            "Document: 135 ausvote, Score: 1.0\n",
            "Document: 151 very engaging, Score: 1.0\n",
            "Document: 170 ausvote   barrel   jaidynlstephenson, Score: 1.0\n",
            "Document: 190 alp                 180, Score: 1.0\n",
            "Document: 194 uap 1359, Score: 1.0\n",
            "Document: 204 ausvote   electionresult, Score: 1.0\n",
            "\n",
            "Query: Coalition\n",
            "Document: 27 auspol, Score: 1.0\n",
            "Document: 71 ausvote, Score: 1.0\n",
            "Document: 90 ausvote usefulidiot, Score: 1.0\n",
            "Document: 100 auspol, Score: 1.0\n",
            "Document: 135 ausvote, Score: 1.0\n",
            "Document: 151 very engaging, Score: 1.0\n",
            "Document: 170 ausvote   barrel   jaidynlstephenson, Score: 1.0\n",
            "Document: 190 alp                 180, Score: 1.0\n",
            "Document: 194 uap 1359, Score: 1.0\n",
            "Document: 204 ausvote   electionresult, Score: 1.0\n",
            "\n",
            "Query: Labor\n",
            "Document: 27 auspol, Score: 1.0\n",
            "Document: 71 ausvote, Score: 1.0\n",
            "Document: 90 ausvote usefulidiot, Score: 1.0\n",
            "Document: 100 auspol, Score: 1.0\n",
            "Document: 135 ausvote, Score: 1.0\n",
            "Document: 151 very engaging, Score: 1.0\n",
            "Document: 170 ausvote   barrel   jaidynlstephenson, Score: 1.0\n",
            "Document: 190 alp                 180, Score: 1.0\n",
            "Document: 194 uap 1359, Score: 1.0\n",
            "Document: 204 ausvote   electionresult, Score: 1.0\n",
            "\n",
            "Query: Liberal\n",
            "Document: 27 auspol, Score: 1.0\n",
            "Document: 71 ausvote, Score: 1.0\n",
            "Document: 90 ausvote usefulidiot, Score: 1.0\n",
            "Document: 100 auspol, Score: 1.0\n",
            "Document: 135 ausvote, Score: 1.0\n",
            "Document: 151 very engaging, Score: 1.0\n",
            "Document: 170 ausvote   barrel   jaidynlstephenson, Score: 1.0\n",
            "Document: 190 alp                 180, Score: 1.0\n",
            "Document: 194 uap 1359, Score: 1.0\n",
            "Document: 204 ausvote   electionresult, Score: 1.0\n",
            "\n",
            "Query: Auspol\n",
            "Document: 27 auspol, Score: 1.0\n",
            "Document: 71 ausvote, Score: 1.0\n",
            "Document: 90 ausvote usefulidiot, Score: 1.0\n",
            "Document: 100 auspol, Score: 1.0\n",
            "Document: 135 ausvote, Score: 1.0\n",
            "Document: 151 very engaging, Score: 1.0\n",
            "Document: 170 ausvote   barrel   jaidynlstephenson, Score: 1.0\n",
            "Document: 190 alp                 180, Score: 1.0\n",
            "Document: 194 uap 1359, Score: 1.0\n",
            "Document: 204 ausvote   electionresult, Score: 1.0\n",
            "\n",
            "Query: Democracy Sausage\n",
            "Document: 27 auspol, Score: 1.0\n",
            "Document: 71 ausvote, Score: 1.0\n",
            "Document: 90 ausvote usefulidiot, Score: 1.0\n",
            "Document: 100 auspol, Score: 1.0\n",
            "Document: 135 ausvote, Score: 1.0\n",
            "Document: 151 very engaging, Score: 1.0\n",
            "Document: 170 ausvote   barrel   jaidynlstephenson, Score: 1.0\n",
            "Document: 190 alp                 180, Score: 1.0\n",
            "Document: 194 uap 1359, Score: 1.0\n",
            "Document: 204 ausvote   electionresult, Score: 1.0\n",
            "\n",
            "Query: Ausvotes\n",
            "Document: 27 auspol, Score: 1.0\n",
            "Document: 71 ausvote, Score: 1.0\n",
            "Document: 90 ausvote usefulidiot, Score: 1.0\n",
            "Document: 100 auspol, Score: 1.0\n",
            "Document: 135 ausvote, Score: 1.0\n",
            "Document: 151 very engaging, Score: 1.0\n",
            "Document: 170 ausvote   barrel   jaidynlstephenson, Score: 1.0\n",
            "Document: 190 alp                 180, Score: 1.0\n",
            "Document: 194 uap 1359, Score: 1.0\n",
            "Document: 204 ausvote   electionresult, Score: 1.0\n",
            "\n",
            "Query: Aus Votes22\n",
            "Document: 27 auspol, Score: 1.0\n",
            "Document: 71 ausvote, Score: 1.0\n",
            "Document: 90 ausvote usefulidiot, Score: 1.0\n",
            "Document: 100 auspol, Score: 1.0\n",
            "Document: 135 ausvote, Score: 1.0\n",
            "Document: 151 very engaging, Score: 1.0\n",
            "Document: 170 ausvote   barrel   jaidynlstephenson, Score: 1.0\n",
            "Document: 190 alp                 180, Score: 1.0\n",
            "Document: 194 uap 1359, Score: 1.0\n",
            "Document: 204 ausvote   electionresult, Score: 1.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "# using the original from lab 4 because it goes line by line instead of needing the full corpus at once\n",
        "def euclidean_distance_based_similarity (vector1, vector2):\n",
        "    distance = np.linalg.norm(np.array(vector1) - np.array(vector2))\n",
        "\n",
        "    # if the distance is 0 then it can be discarded, otherwise return it\n",
        "    if distance == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1 / (np.linalg.norm(np.array(vector1) - np.array(vector2)))\n",
        "# repeat for each hashtag\n",
        "for hashtag in hashtags:\n",
        "    query_vector = vectorizer.transform([hashtag]).toarray()[0]\n",
        "\n",
        "    # this is all taken from lab 4\n",
        "    similarity_scores = {}\n",
        "    for i, tweet_vector in enumerate(tweet_vectors):\n",
        "        sim = euclidean_distance_based_similarity(tweet_vector, query_vector)\n",
        "        similarity_scores[i] = sim\n",
        "    ranked_documents = sorted(similarity_scores.items(),key=lambda x: x[1], reverse = True)\n",
        "    # print the top 10 documents based on ranked score\n",
        "    print (f\"\\nQuery: {hashtag}\")\n",
        "    for document_idx, score in ranked_documents[:10]:\n",
        "        print(f\"Document: {document_idx} {prepro_tweets[document_idx]}, Score: {score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[Before fix]\n",
        "\n",
        "This is not working as expected. There are a lot of cases where there is a divide by 0, which is resulting in infinite. I will change that so that all infinite cases are removed.\n",
        "\n",
        "[After fix]\n",
        "\n",
        "Ok, now it is working as expected. As expected, the top 10 of each hashtag are tweets that are *just* the hashtag, and nothing else. Frankly, this does not tell me a lot about what is similar, so maybe in the future I will remove that, but for now I will let it stay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 2: Use TfIdfVectorizer  vectorization technique and perform search\n",
        "\n",
        "We do the same thing as above but with TfIdfVectorizer instead\n",
        "\n",
        "So we make the vectorizer, vectorize the tweets with it, define hashtags, normalize & vectorize them, and then perform similarity search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Query: Renewable Energy\n",
            "Document: 0 voting complete in nyc now for democracy sausage auspol, Score: 1.0000000000000002\n",
            "Document: 13 australias labor party weigh up future after shock election defeat, Score: 1.0000000000000002\n",
            "Document: 21 tomorrow from 8309am abcsydney live election forum with instudio audience, Score: 1.0000000000000002\n",
            "Document: 26 coalitionman you know it be not the pole fault it be russia, Score: 1.0000000000000002\n",
            "Document: 28 2019 australia election generational issue dominate vote a record number be register to vote in a poll that come month after a brutal leadership tussle, Score: 1.0000000000000002\n",
            "Document: 31 beware the opinion pollster, Score: 1.0000000000000002\n",
            "Document: 34 auspol how about horrendous allege rape of 16 yo girl at labor youth camp by labor leader billshorten in 1986 gt new evidence go to vicpolice to reopen case yesterday he could be our next laborliar pm gt do that charming story bias theirabc abcnews no bet not, Score: 1.0000000000000002\n",
            "Document: 41 seqularleft mozbekau both actually auspol, Score: 1.0000000000000002\n",
            "Document: 42 qanda pollution fracke, Score: 1.0000000000000002\n",
            "Document: 46 pretty sure that fuckin clive palmer ad on tv just go for 10 minute what that actual fuck auspol australiavotes2019, Score: 1.0000000000000002\n",
            "\n",
            "Query: Tax Laws\n",
            "Document: 0 voting complete in nyc now for democracy sausage auspol, Score: 1.0000000000000002\n",
            "Document: 13 australias labor party weigh up future after shock election defeat, Score: 1.0000000000000002\n",
            "Document: 21 tomorrow from 8309am abcsydney live election forum with instudio audience, Score: 1.0000000000000002\n",
            "Document: 26 coalitionman you know it be not the pole fault it be russia, Score: 1.0000000000000002\n",
            "Document: 28 2019 australia election generational issue dominate vote a record number be register to vote in a poll that come month after a brutal leadership tussle, Score: 1.0000000000000002\n",
            "Document: 31 beware the opinion pollster, Score: 1.0000000000000002\n",
            "Document: 34 auspol how about horrendous allege rape of 16 yo girl at labor youth camp by labor leader billshorten in 1986 gt new evidence go to vicpolice to reopen case yesterday he could be our next laborliar pm gt do that charming story bias theirabc abcnews no bet not, Score: 1.0000000000000002\n",
            "Document: 41 seqularleft mozbekau both actually auspol, Score: 1.0000000000000002\n",
            "Document: 42 qanda pollution fracke, Score: 1.0000000000000002\n",
            "Document: 46 pretty sure that fuckin clive palmer ad on tv just go for 10 minute what that actual fuck auspol australiavotes2019, Score: 1.0000000000000002\n",
            "\n",
            "Query: Parliamentary Majority\n",
            "Document: 0 voting complete in nyc now for democracy sausage auspol, Score: 1.0000000000000002\n",
            "Document: 13 australias labor party weigh up future after shock election defeat, Score: 1.0000000000000002\n",
            "Document: 21 tomorrow from 8309am abcsydney live election forum with instudio audience, Score: 1.0000000000000002\n",
            "Document: 26 coalitionman you know it be not the pole fault it be russia, Score: 1.0000000000000002\n",
            "Document: 28 2019 australia election generational issue dominate vote a record number be register to vote in a poll that come month after a brutal leadership tussle, Score: 1.0000000000000002\n",
            "Document: 31 beware the opinion pollster, Score: 1.0000000000000002\n",
            "Document: 34 auspol how about horrendous allege rape of 16 yo girl at labor youth camp by labor leader billshorten in 1986 gt new evidence go to vicpolice to reopen case yesterday he could be our next laborliar pm gt do that charming story bias theirabc abcnews no bet not, Score: 1.0000000000000002\n",
            "Document: 41 seqularleft mozbekau both actually auspol, Score: 1.0000000000000002\n",
            "Document: 42 qanda pollution fracke, Score: 1.0000000000000002\n",
            "Document: 46 pretty sure that fuckin clive palmer ad on tv just go for 10 minute what that actual fuck auspol australiavotes2019, Score: 1.0000000000000002\n",
            "\n",
            "Query: Coalition\n",
            "Document: 0 voting complete in nyc now for democracy sausage auspol, Score: 1.0000000000000002\n",
            "Document: 13 australias labor party weigh up future after shock election defeat, Score: 1.0000000000000002\n",
            "Document: 21 tomorrow from 8309am abcsydney live election forum with instudio audience, Score: 1.0000000000000002\n",
            "Document: 26 coalitionman you know it be not the pole fault it be russia, Score: 1.0000000000000002\n",
            "Document: 28 2019 australia election generational issue dominate vote a record number be register to vote in a poll that come month after a brutal leadership tussle, Score: 1.0000000000000002\n",
            "Document: 31 beware the opinion pollster, Score: 1.0000000000000002\n",
            "Document: 34 auspol how about horrendous allege rape of 16 yo girl at labor youth camp by labor leader billshorten in 1986 gt new evidence go to vicpolice to reopen case yesterday he could be our next laborliar pm gt do that charming story bias theirabc abcnews no bet not, Score: 1.0000000000000002\n",
            "Document: 41 seqularleft mozbekau both actually auspol, Score: 1.0000000000000002\n",
            "Document: 42 qanda pollution fracke, Score: 1.0000000000000002\n",
            "Document: 46 pretty sure that fuckin clive palmer ad on tv just go for 10 minute what that actual fuck auspol australiavotes2019, Score: 1.0000000000000002\n",
            "\n",
            "Query: Labor\n",
            "Document: 0 voting complete in nyc now for democracy sausage auspol, Score: 1.0000000000000002\n",
            "Document: 13 australias labor party weigh up future after shock election defeat, Score: 1.0000000000000002\n",
            "Document: 21 tomorrow from 8309am abcsydney live election forum with instudio audience, Score: 1.0000000000000002\n",
            "Document: 26 coalitionman you know it be not the pole fault it be russia, Score: 1.0000000000000002\n",
            "Document: 28 2019 australia election generational issue dominate vote a record number be register to vote in a poll that come month after a brutal leadership tussle, Score: 1.0000000000000002\n",
            "Document: 31 beware the opinion pollster, Score: 1.0000000000000002\n",
            "Document: 34 auspol how about horrendous allege rape of 16 yo girl at labor youth camp by labor leader billshorten in 1986 gt new evidence go to vicpolice to reopen case yesterday he could be our next laborliar pm gt do that charming story bias theirabc abcnews no bet not, Score: 1.0000000000000002\n",
            "Document: 41 seqularleft mozbekau both actually auspol, Score: 1.0000000000000002\n",
            "Document: 42 qanda pollution fracke, Score: 1.0000000000000002\n",
            "Document: 46 pretty sure that fuckin clive palmer ad on tv just go for 10 minute what that actual fuck auspol australiavotes2019, Score: 1.0000000000000002\n",
            "\n",
            "Query: Liberal\n",
            "Document: 0 voting complete in nyc now for democracy sausage auspol, Score: 1.0000000000000002\n",
            "Document: 13 australias labor party weigh up future after shock election defeat, Score: 1.0000000000000002\n",
            "Document: 21 tomorrow from 8309am abcsydney live election forum with instudio audience, Score: 1.0000000000000002\n",
            "Document: 26 coalitionman you know it be not the pole fault it be russia, Score: 1.0000000000000002\n",
            "Document: 28 2019 australia election generational issue dominate vote a record number be register to vote in a poll that come month after a brutal leadership tussle, Score: 1.0000000000000002\n",
            "Document: 31 beware the opinion pollster, Score: 1.0000000000000002\n",
            "Document: 34 auspol how about horrendous allege rape of 16 yo girl at labor youth camp by labor leader billshorten in 1986 gt new evidence go to vicpolice to reopen case yesterday he could be our next laborliar pm gt do that charming story bias theirabc abcnews no bet not, Score: 1.0000000000000002\n",
            "Document: 41 seqularleft mozbekau both actually auspol, Score: 1.0000000000000002\n",
            "Document: 42 qanda pollution fracke, Score: 1.0000000000000002\n",
            "Document: 46 pretty sure that fuckin clive palmer ad on tv just go for 10 minute what that actual fuck auspol australiavotes2019, Score: 1.0000000000000002\n",
            "\n",
            "Query: Auspol\n",
            "Document: 0 voting complete in nyc now for democracy sausage auspol, Score: 1.0000000000000002\n",
            "Document: 13 australias labor party weigh up future after shock election defeat, Score: 1.0000000000000002\n",
            "Document: 21 tomorrow from 8309am abcsydney live election forum with instudio audience, Score: 1.0000000000000002\n",
            "Document: 26 coalitionman you know it be not the pole fault it be russia, Score: 1.0000000000000002\n",
            "Document: 28 2019 australia election generational issue dominate vote a record number be register to vote in a poll that come month after a brutal leadership tussle, Score: 1.0000000000000002\n",
            "Document: 31 beware the opinion pollster, Score: 1.0000000000000002\n",
            "Document: 34 auspol how about horrendous allege rape of 16 yo girl at labor youth camp by labor leader billshorten in 1986 gt new evidence go to vicpolice to reopen case yesterday he could be our next laborliar pm gt do that charming story bias theirabc abcnews no bet not, Score: 1.0000000000000002\n",
            "Document: 41 seqularleft mozbekau both actually auspol, Score: 1.0000000000000002\n",
            "Document: 42 qanda pollution fracke, Score: 1.0000000000000002\n",
            "Document: 46 pretty sure that fuckin clive palmer ad on tv just go for 10 minute what that actual fuck auspol australiavotes2019, Score: 1.0000000000000002\n",
            "\n",
            "Query: Democracy Sausage\n",
            "Document: 0 voting complete in nyc now for democracy sausage auspol, Score: 1.0000000000000002\n",
            "Document: 13 australias labor party weigh up future after shock election defeat, Score: 1.0000000000000002\n",
            "Document: 21 tomorrow from 8309am abcsydney live election forum with instudio audience, Score: 1.0000000000000002\n",
            "Document: 26 coalitionman you know it be not the pole fault it be russia, Score: 1.0000000000000002\n",
            "Document: 28 2019 australia election generational issue dominate vote a record number be register to vote in a poll that come month after a brutal leadership tussle, Score: 1.0000000000000002\n",
            "Document: 31 beware the opinion pollster, Score: 1.0000000000000002\n",
            "Document: 34 auspol how about horrendous allege rape of 16 yo girl at labor youth camp by labor leader billshorten in 1986 gt new evidence go to vicpolice to reopen case yesterday he could be our next laborliar pm gt do that charming story bias theirabc abcnews no bet not, Score: 1.0000000000000002\n",
            "Document: 41 seqularleft mozbekau both actually auspol, Score: 1.0000000000000002\n",
            "Document: 42 qanda pollution fracke, Score: 1.0000000000000002\n",
            "Document: 46 pretty sure that fuckin clive palmer ad on tv just go for 10 minute what that actual fuck auspol australiavotes2019, Score: 1.0000000000000002\n",
            "\n",
            "Query: Ausvotes\n",
            "Document: 0 voting complete in nyc now for democracy sausage auspol, Score: 1.0000000000000002\n",
            "Document: 13 australias labor party weigh up future after shock election defeat, Score: 1.0000000000000002\n",
            "Document: 21 tomorrow from 8309am abcsydney live election forum with instudio audience, Score: 1.0000000000000002\n",
            "Document: 26 coalitionman you know it be not the pole fault it be russia, Score: 1.0000000000000002\n",
            "Document: 28 2019 australia election generational issue dominate vote a record number be register to vote in a poll that come month after a brutal leadership tussle, Score: 1.0000000000000002\n",
            "Document: 31 beware the opinion pollster, Score: 1.0000000000000002\n",
            "Document: 34 auspol how about horrendous allege rape of 16 yo girl at labor youth camp by labor leader billshorten in 1986 gt new evidence go to vicpolice to reopen case yesterday he could be our next laborliar pm gt do that charming story bias theirabc abcnews no bet not, Score: 1.0000000000000002\n",
            "Document: 41 seqularleft mozbekau both actually auspol, Score: 1.0000000000000002\n",
            "Document: 42 qanda pollution fracke, Score: 1.0000000000000002\n",
            "Document: 46 pretty sure that fuckin clive palmer ad on tv just go for 10 minute what that actual fuck auspol australiavotes2019, Score: 1.0000000000000002\n",
            "\n",
            "Query: Aus Votes22\n",
            "Document: 0 voting complete in nyc now for democracy sausage auspol, Score: 1.0000000000000002\n",
            "Document: 13 australias labor party weigh up future after shock election defeat, Score: 1.0000000000000002\n",
            "Document: 21 tomorrow from 8309am abcsydney live election forum with instudio audience, Score: 1.0000000000000002\n",
            "Document: 26 coalitionman you know it be not the pole fault it be russia, Score: 1.0000000000000002\n",
            "Document: 28 2019 australia election generational issue dominate vote a record number be register to vote in a poll that come month after a brutal leadership tussle, Score: 1.0000000000000002\n",
            "Document: 31 beware the opinion pollster, Score: 1.0000000000000002\n",
            "Document: 34 auspol how about horrendous allege rape of 16 yo girl at labor youth camp by labor leader billshorten in 1986 gt new evidence go to vicpolice to reopen case yesterday he could be our next laborliar pm gt do that charming story bias theirabc abcnews no bet not, Score: 1.0000000000000002\n",
            "Document: 41 seqularleft mozbekau both actually auspol, Score: 1.0000000000000002\n",
            "Document: 42 qanda pollution fracke, Score: 1.0000000000000002\n",
            "Document: 46 pretty sure that fuckin clive palmer ad on tv just go for 10 minute what that actual fuck auspol australiavotes2019, Score: 1.0000000000000002\n"
          ]
        }
      ],
      "source": [
        "# still taken from lab 4\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# N is still 1\n",
        "vectorizer = TfidfVectorizer(ngram_range=(N, N), lowercase = False, binary = True, max_features = 3000) # very low for now. I can't have it be too high\n",
        "vectorizer.fit(prepro_tweets)\n",
        "vocab = vectorizer.get_feature_names_out()\n",
        "\n",
        "# making a transformation of each tweet (very memory intensive and a complete space hog)\n",
        "tweet_vectors = []\n",
        "\n",
        "# prepro_tweets is still 1000 in size\n",
        "for sentence in prepro_tweets:\n",
        "  transformed_vector = vectorizer.transform([sentence])\n",
        "  tweet_vectors.append(transformed_vector.toarray()[0])\n",
        "\n",
        "# Processing hashtags is already done, no need to do it further\n",
        "# the euclidian distance function is also already done\n",
        "\n",
        "# repeat for each hashtag\n",
        "for hashtag in hashtags:\n",
        "    query_vector = vectorizer.transform([hashtag]).toarray()[0]\n",
        "\n",
        "    # this is all taken from lab 4\n",
        "    similarity_scores = {}\n",
        "    for i, tweet_vector in enumerate(tweet_vectors):\n",
        "        sim = euclidean_distance_based_similarity(tweet_vector, query_vector)\n",
        "        similarity_scores[i] = sim\n",
        "    ranked_documents = sorted(similarity_scores.items(),key=lambda x: x[1], reverse = True)\n",
        "    # print the top 10 documents based on ranked score\n",
        "    print (f\"\\nQuery: {hashtag}\")\n",
        "    for document_idx, score in ranked_documents[:10]:\n",
        "        print(f\"Document: {document_idx} {prepro_tweets[document_idx]}, Score: {score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is really different it seems, it's getting that the euclidian distances between vectors is < 1, which leads to similarity scores over 1! This should not technically happen, but I really don't know what the problem is, and I'm short on time so I'll let it go for now."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 3: Use WordEmbedding vectorization technique and perform search\n",
        "\n",
        "1. Repeat Task 1 steps but use Glove Vectors (\"glove-wiki-gigaword-50\") to extract word embedding and then convert all word embeddings into sentence embedding by averaging the word embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# straight out of lab 4 again!\n",
        "\n",
        "from gensim.models import KeyedVectors\n",
        "import gensim.downloader as api\n",
        "\n",
        "# Load pre-trained GloVe embeddings\n",
        "word_vectors = api.load(\"glove-wiki-gigaword-50\")\n",
        "\n",
        "# Function to generate average word vectors for a sentence\n",
        "def average_word_embeddings(sentence):\n",
        "    words = sentence.split()\n",
        "    embeddings = []\n",
        "    for word in words:\n",
        "        if word in word_vectors:\n",
        "            embeddings.append(word_vectors[word])\n",
        "    if len(embeddings) > 0:\n",
        "        # is word vector exists for the word\n",
        "        return np.mean(embeddings, axis=0)\n",
        "    else:\n",
        "        return np.zeros(word_vectors.vector_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Query: Renewable Energy\n",
            "Document: 560 skynewsaust scottmorrisonmp oh ffs   morrison turnbull abbott high tax ng govt sincehoward   auspol ausvotes2019 msm, Score: 0.511864672832316\n",
            "Document: 832 eurovision2019 vote kmillerheidke australia awesome queenslander qld brisbane topclass corinda, Score: 0.4718485538749829\n",
            "Document: 598 liberal james stevens lead labors cressida ohanlon comfortably in sturt live update   auspol ausvote, Score: 0.4658693080011748\n",
            "Document: 250 hotham vic   137 count, Score: 0.45786288794181984\n",
            "Document: 308 dutton be untouchable fucking untouchable auspol depress, Score: 0.4409414970177699\n",
            "Document: 630 wat pn murdoch auspol, Score: 0.4320281914406413\n",
            "Document: 694 menzie voter have a choice stella yee or, Score: 0.43011942859537405\n",
            "Document: 226 albanese v plibersek v bowen who s your pick auspol ausvote ausvotes19, Score: 0.425023810091644\n",
            "Document: 781 wow   bodexpress iceland ausvote btsxmetlife ufcrochester preakness mixer, Score: 0.4027776785291585\n",
            "Document: 572 late murdoch attack on zali steggall, Score: 0.39687490860154573\n",
            "\n",
            "Query: Tax Laws\n",
            "Document: 560 skynewsaust scottmorrisonmp oh ffs   morrison turnbull abbott high tax ng govt sincehoward   auspol ausvotes2019 msm, Score: 0.511864672832316\n",
            "Document: 832 eurovision2019 vote kmillerheidke australia awesome queenslander qld brisbane topclass corinda, Score: 0.4718485538749829\n",
            "Document: 598 liberal james stevens lead labors cressida ohanlon comfortably in sturt live update   auspol ausvote, Score: 0.4658693080011748\n",
            "Document: 250 hotham vic   137 count, Score: 0.45786288794181984\n",
            "Document: 308 dutton be untouchable fucking untouchable auspol depress, Score: 0.4409414970177699\n",
            "Document: 630 wat pn murdoch auspol, Score: 0.4320281914406413\n",
            "Document: 694 menzie voter have a choice stella yee or, Score: 0.43011942859537405\n",
            "Document: 226 albanese v plibersek v bowen who s your pick auspol ausvote ausvotes19, Score: 0.425023810091644\n",
            "Document: 781 wow   bodexpress iceland ausvote btsxmetlife ufcrochester preakness mixer, Score: 0.4027776785291585\n",
            "Document: 572 late murdoch attack on zali steggall, Score: 0.39687490860154573\n",
            "\n",
            "Query: Parliamentary Majority\n",
            "Document: 560 skynewsaust scottmorrisonmp oh ffs   morrison turnbull abbott high tax ng govt sincehoward   auspol ausvotes2019 msm, Score: 0.511864672832316\n",
            "Document: 832 eurovision2019 vote kmillerheidke australia awesome queenslander qld brisbane topclass corinda, Score: 0.4718485538749829\n",
            "Document: 598 liberal james stevens lead labors cressida ohanlon comfortably in sturt live update   auspol ausvote, Score: 0.4658693080011748\n",
            "Document: 250 hotham vic   137 count, Score: 0.45786288794181984\n",
            "Document: 308 dutton be untouchable fucking untouchable auspol depress, Score: 0.4409414970177699\n",
            "Document: 630 wat pn murdoch auspol, Score: 0.4320281914406413\n",
            "Document: 694 menzie voter have a choice stella yee or, Score: 0.43011942859537405\n",
            "Document: 226 albanese v plibersek v bowen who s your pick auspol ausvote ausvotes19, Score: 0.425023810091644\n",
            "Document: 781 wow   bodexpress iceland ausvote btsxmetlife ufcrochester preakness mixer, Score: 0.4027776785291585\n",
            "Document: 572 late murdoch attack on zali steggall, Score: 0.39687490860154573\n",
            "\n",
            "Query: Coalition\n",
            "Document: 560 skynewsaust scottmorrisonmp oh ffs   morrison turnbull abbott high tax ng govt sincehoward   auspol ausvotes2019 msm, Score: 0.511864672832316\n",
            "Document: 832 eurovision2019 vote kmillerheidke australia awesome queenslander qld brisbane topclass corinda, Score: 0.4718485538749829\n",
            "Document: 598 liberal james stevens lead labors cressida ohanlon comfortably in sturt live update   auspol ausvote, Score: 0.4658693080011748\n",
            "Document: 250 hotham vic   137 count, Score: 0.45786288794181984\n",
            "Document: 308 dutton be untouchable fucking untouchable auspol depress, Score: 0.4409414970177699\n",
            "Document: 630 wat pn murdoch auspol, Score: 0.4320281914406413\n",
            "Document: 694 menzie voter have a choice stella yee or, Score: 0.43011942859537405\n",
            "Document: 226 albanese v plibersek v bowen who s your pick auspol ausvote ausvotes19, Score: 0.425023810091644\n",
            "Document: 781 wow   bodexpress iceland ausvote btsxmetlife ufcrochester preakness mixer, Score: 0.4027776785291585\n",
            "Document: 572 late murdoch attack on zali steggall, Score: 0.39687490860154573\n",
            "\n",
            "Query: Labor\n",
            "Document: 560 skynewsaust scottmorrisonmp oh ffs   morrison turnbull abbott high tax ng govt sincehoward   auspol ausvotes2019 msm, Score: 0.511864672832316\n",
            "Document: 832 eurovision2019 vote kmillerheidke australia awesome queenslander qld brisbane topclass corinda, Score: 0.4718485538749829\n",
            "Document: 598 liberal james stevens lead labors cressida ohanlon comfortably in sturt live update   auspol ausvote, Score: 0.4658693080011748\n",
            "Document: 250 hotham vic   137 count, Score: 0.45786288794181984\n",
            "Document: 308 dutton be untouchable fucking untouchable auspol depress, Score: 0.4409414970177699\n",
            "Document: 630 wat pn murdoch auspol, Score: 0.4320281914406413\n",
            "Document: 694 menzie voter have a choice stella yee or, Score: 0.43011942859537405\n",
            "Document: 226 albanese v plibersek v bowen who s your pick auspol ausvote ausvotes19, Score: 0.425023810091644\n",
            "Document: 781 wow   bodexpress iceland ausvote btsxmetlife ufcrochester preakness mixer, Score: 0.4027776785291585\n",
            "Document: 572 late murdoch attack on zali steggall, Score: 0.39687490860154573\n",
            "\n",
            "Query: Liberal\n",
            "Document: 560 skynewsaust scottmorrisonmp oh ffs   morrison turnbull abbott high tax ng govt sincehoward   auspol ausvotes2019 msm, Score: 0.511864672832316\n",
            "Document: 832 eurovision2019 vote kmillerheidke australia awesome queenslander qld brisbane topclass corinda, Score: 0.4718485538749829\n",
            "Document: 598 liberal james stevens lead labors cressida ohanlon comfortably in sturt live update   auspol ausvote, Score: 0.4658693080011748\n",
            "Document: 250 hotham vic   137 count, Score: 0.45786288794181984\n",
            "Document: 308 dutton be untouchable fucking untouchable auspol depress, Score: 0.4409414970177699\n",
            "Document: 630 wat pn murdoch auspol, Score: 0.4320281914406413\n",
            "Document: 694 menzie voter have a choice stella yee or, Score: 0.43011942859537405\n",
            "Document: 226 albanese v plibersek v bowen who s your pick auspol ausvote ausvotes19, Score: 0.425023810091644\n",
            "Document: 781 wow   bodexpress iceland ausvote btsxmetlife ufcrochester preakness mixer, Score: 0.4027776785291585\n",
            "Document: 572 late murdoch attack on zali steggall, Score: 0.39687490860154573\n",
            "\n",
            "Query: Auspol\n",
            "Document: 560 skynewsaust scottmorrisonmp oh ffs   morrison turnbull abbott high tax ng govt sincehoward   auspol ausvotes2019 msm, Score: 0.511864672832316\n",
            "Document: 832 eurovision2019 vote kmillerheidke australia awesome queenslander qld brisbane topclass corinda, Score: 0.4718485538749829\n",
            "Document: 598 liberal james stevens lead labors cressida ohanlon comfortably in sturt live update   auspol ausvote, Score: 0.4658693080011748\n",
            "Document: 250 hotham vic   137 count, Score: 0.45786288794181984\n",
            "Document: 308 dutton be untouchable fucking untouchable auspol depress, Score: 0.4409414970177699\n",
            "Document: 630 wat pn murdoch auspol, Score: 0.4320281914406413\n",
            "Document: 694 menzie voter have a choice stella yee or, Score: 0.43011942859537405\n",
            "Document: 226 albanese v plibersek v bowen who s your pick auspol ausvote ausvotes19, Score: 0.425023810091644\n",
            "Document: 781 wow   bodexpress iceland ausvote btsxmetlife ufcrochester preakness mixer, Score: 0.4027776785291585\n",
            "Document: 572 late murdoch attack on zali steggall, Score: 0.39687490860154573\n",
            "\n",
            "Query: Democracy Sausage\n",
            "Document: 560 skynewsaust scottmorrisonmp oh ffs   morrison turnbull abbott high tax ng govt sincehoward   auspol ausvotes2019 msm, Score: 0.511864672832316\n",
            "Document: 832 eurovision2019 vote kmillerheidke australia awesome queenslander qld brisbane topclass corinda, Score: 0.4718485538749829\n",
            "Document: 598 liberal james stevens lead labors cressida ohanlon comfortably in sturt live update   auspol ausvote, Score: 0.4658693080011748\n",
            "Document: 250 hotham vic   137 count, Score: 0.45786288794181984\n",
            "Document: 308 dutton be untouchable fucking untouchable auspol depress, Score: 0.4409414970177699\n",
            "Document: 630 wat pn murdoch auspol, Score: 0.4320281914406413\n",
            "Document: 694 menzie voter have a choice stella yee or, Score: 0.43011942859537405\n",
            "Document: 226 albanese v plibersek v bowen who s your pick auspol ausvote ausvotes19, Score: 0.425023810091644\n",
            "Document: 781 wow   bodexpress iceland ausvote btsxmetlife ufcrochester preakness mixer, Score: 0.4027776785291585\n",
            "Document: 572 late murdoch attack on zali steggall, Score: 0.39687490860154573\n",
            "\n",
            "Query: Ausvotes\n",
            "Document: 560 skynewsaust scottmorrisonmp oh ffs   morrison turnbull abbott high tax ng govt sincehoward   auspol ausvotes2019 msm, Score: 0.511864672832316\n",
            "Document: 832 eurovision2019 vote kmillerheidke australia awesome queenslander qld brisbane topclass corinda, Score: 0.4718485538749829\n",
            "Document: 598 liberal james stevens lead labors cressida ohanlon comfortably in sturt live update   auspol ausvote, Score: 0.4658693080011748\n",
            "Document: 250 hotham vic   137 count, Score: 0.45786288794181984\n",
            "Document: 308 dutton be untouchable fucking untouchable auspol depress, Score: 0.4409414970177699\n",
            "Document: 630 wat pn murdoch auspol, Score: 0.4320281914406413\n",
            "Document: 694 menzie voter have a choice stella yee or, Score: 0.43011942859537405\n",
            "Document: 226 albanese v plibersek v bowen who s your pick auspol ausvote ausvotes19, Score: 0.425023810091644\n",
            "Document: 781 wow   bodexpress iceland ausvote btsxmetlife ufcrochester preakness mixer, Score: 0.4027776785291585\n",
            "Document: 572 late murdoch attack on zali steggall, Score: 0.39687490860154573\n",
            "\n",
            "Query: Aus Votes22\n",
            "Document: 560 skynewsaust scottmorrisonmp oh ffs   morrison turnbull abbott high tax ng govt sincehoward   auspol ausvotes2019 msm, Score: 0.511864672832316\n",
            "Document: 832 eurovision2019 vote kmillerheidke australia awesome queenslander qld brisbane topclass corinda, Score: 0.4718485538749829\n",
            "Document: 598 liberal james stevens lead labors cressida ohanlon comfortably in sturt live update   auspol ausvote, Score: 0.4658693080011748\n",
            "Document: 250 hotham vic   137 count, Score: 0.45786288794181984\n",
            "Document: 308 dutton be untouchable fucking untouchable auspol depress, Score: 0.4409414970177699\n",
            "Document: 630 wat pn murdoch auspol, Score: 0.4320281914406413\n",
            "Document: 694 menzie voter have a choice stella yee or, Score: 0.43011942859537405\n",
            "Document: 226 albanese v plibersek v bowen who s your pick auspol ausvote ausvotes19, Score: 0.425023810091644\n",
            "Document: 781 wow   bodexpress iceland ausvote btsxmetlife ufcrochester preakness mixer, Score: 0.4027776785291585\n",
            "Document: 572 late murdoch attack on zali steggall, Score: 0.39687490860154573\n"
          ]
        }
      ],
      "source": [
        "word_vector_tweets = []\n",
        "\n",
        "for sentence in prepro_tweets:\n",
        "  transformed_vector = average_word_embeddings(sentence)\n",
        "  word_vector_tweets.append(transformed_vector)\n",
        "\n",
        "# Processing hashtags is already done, no need to do it further\n",
        "# the euclidian distance function is also already done\n",
        "\n",
        "# repeat for each hashtag\n",
        "for hashtag in hashtags:\n",
        "    query_vector = average_word_embeddings(hashtag)\n",
        "\n",
        "    # this is all copied from above\n",
        "    similarity_scores = {}\n",
        "    for i, tweet_vector in enumerate(word_vector_tweets):\n",
        "        sim = euclidean_distance_based_similarity(tweet_vector, query_vector)\n",
        "        similarity_scores[i] = sim\n",
        "    ranked_documents = sorted(similarity_scores.items(),key=lambda x: x[1], reverse = True)\n",
        "    # print the top 10 documents based on ranked score\n",
        "    print (f\"\\nQuery: {hashtag}\")\n",
        "    for document_idx, score in ranked_documents[:10]:\n",
        "        print(f\"Document: {document_idx} {prepro_tweets[document_idx]}, Score: {score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This one is a little surprising. The scores are lower than the count or the tf-idf vectorizer, but maybe that's to be expected, and that using a bigger word model may produce better results that way.\n",
        "\n",
        "Another way to look at it is that this model may be more accurate, as it's able to figure out words that are not exactly the search hashtag and weight it properly. This could be beneficial, but without further research I cannot say for certain if what I see here is true.\n",
        "\n",
        "Another thing to note is that this is done on a sample of 1000 words, which will probably hamper the results somewhat for *all* the vectorizing models involved. If/when I get a beefier computer I will try to run this thing at full speed."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPj6Ccw9Pq/vRcnXnqi8vu9",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
