{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 1. Basic Text Processing with Python\n",
        "\n",
        "Note: this is a lab session graded. Complete all exercises and upload to Canvas under **Lab 1: Python basics for text analysis** by no later than 01/18/2023, 11:59 PM\n",
        "\n",
        "Let's do a quick recap on string processing with Python. For string processing, you should go over this tutorial : https://www.geeksforgeeks.org/python-string/"
      ],
      "metadata": {
        "id": "C1MJZYHc-0cN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's start some basic coding\n",
        "\n",
        "str1 = \"Hello, \"\n",
        "str2 = \"world!\"\n",
        "result = str1 + str2\n",
        "\n",
        "print(result)  # Output: Hello, world!\n",
        "\n",
        "# String length\n",
        "text = \"Python is awesome\"\n",
        "length = len(text)\n",
        "print(length)  # Output: 17\n",
        "\n",
        "# String slicing\n",
        "text = \"Python is fun\"\n",
        "sub_string = text[7:9]  # Extracts \"is\"\n",
        "print(sub_string)\n",
        "\n",
        "# String methods\n",
        "text = \"   Python Programming   \"\n",
        "stripped = text.strip()         # Removes leading/trailing whitespace\n",
        "upper_case = text.upper()       # Converts to uppercase\n",
        "lower_case = text.lower()       # Converts to lowercase\n",
        "replaced = text.replace(\"P\", \"C\")  # Replaces \"P\" with \"C\"\n",
        "\n",
        "# String joining\n",
        "words = ['Python', 'is', 'awesome']\n",
        "sentence = ' '.join(words)\n",
        "print(sentence)  # Output: \"Python is awesome\"\n",
        "\n",
        "# String Formatting\n",
        "name = \"Alice\"\n",
        "age = 30\n",
        "message = \"My name is {} and I am {} years old.\".format(name, age)\n",
        "print(message)\n",
        "\n",
        "# Searching in String\n",
        "\n",
        "text = \"Python is powerful\"\n",
        "if \"powerful\" in text:\n",
        "    print(\"Substring found\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iVkTSYf-7NH",
        "outputId": "4ca355c4-d462-490a-9a89-9b80e629ccec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, world!\n",
            "17\n",
            "is\n",
            "Python is awesome\n",
            "My name is Alice and I am 30 years old.\n",
            "Substring found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lists from strings, and hashing strings in dictionary"
      ],
      "metadata": {
        "id": "tccQhBE9__3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Python is great for programming\"\n",
        "word_list = sentence.split()\n",
        "print(word_list)  # Output: ['Python', 'is', 'great', 'for', 'programming']\n",
        "\n",
        "#list slicing\n",
        "\n",
        "print (word_list[:5])\n",
        "\n",
        "import json\n",
        "\n",
        "json_string = '{\"name\": \"Bob\", \"age\": 30, \"city\": \"London\"}'\n",
        "data_dict = json.loads(json_string)\n",
        "print(data_dict)  # Output: {'name': 'Bob', 'age': 30, 'city': 'London'}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6d7Lyfw_9-D",
        "outputId": "4f107a50-46aa-48a7-ed4f-1e4dee8fd53c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Python', 'is', 'great', 'for', 'programming']\n",
            "['Python', 'is', 'great', 'for', 'programming']\n",
            "{'name': 'Bob', 'age': 30, 'city': 'London'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise E1. Processing wikipedia text\n",
        "\n",
        "- Implement a function for scraping a website using the BeautifulSoup library. You can refer to the code here\n",
        "```\n",
        "https://stackoverflow.com/questions/1936466/how-to-scrape-only-visible-webpage-text-with-beautifulsoup\n",
        "```\n",
        "- Extract all text from the website https://en.wikipedia.org/wiki/Natural_language_processing, store it in a variable.\n",
        "\n",
        "- Extract all words from the paragraph using split() method. Try to remove words that are too common (also known as StopWords) (E.g., `is`, `are`, `of`, `a`, in general articles, prepositions, auxiliary verbs etc)  You can define a list of such common words manually and remove them (example given below).\n",
        "\n",
        "```\n",
        "stop_words = [\"the\", \"and\", \"in\", \"to\", \"of\", \"a\", \"is\", \"it\", \"for\", \"on\"]\n",
        "\n",
        "```\n",
        "\n",
        "- Now, after removing redundant words, make a dictionary of frequency of words. e.g. {\"language\": 5, \"processing\": 10}\n",
        "\n",
        "- Print a ranked order of words by sorting the dictionary. Print the ranked order\n",
        "\n",
        "- Create a bar graph showing words in the x-axis and frequeny in the y axis using `matplotlib`. You can take help of the reference below:\n",
        "\n",
        "```\n",
        "https://stackoverflow.com/questions/64684351/plotting-a-bar-chart-of-sorted-word-frequencies\n",
        "```\n",
        "\n",
        "- A better understanding of emphasis of words can be attained by plotting WordClouds (Reference: https://en.wikipedia.org/wiki/Tag_cloud). Make a word cloud from the frequency dictionary that you built.\n",
        "\n",
        "  You can use the following snippet to install and import the WordCloud package.\n",
        "\n",
        "  ```\n",
        "  !pip install WordCloud\n",
        "  from wordcloud import WordCloud\n",
        "  ```\n",
        "\n",
        "  Check this solution here and figure out how to plot word clouds from frequencies. You can copy paste the code from the website as long as you give proper attribution in a Markdown block.\n",
        "\n",
        "  ```\n",
        "  https://stackoverflow.com/questions/38465478/wordcloud-from-data-frame-with-frequency-python\n",
        "  ```\n",
        "- Write down your observations in a mark down block.\n",
        "\n"
      ],
      "metadata": {
        "id": "_ssjNAdbCE8p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [Optional] E2. Repeat E1 for the chinese page https://zh.wikipedia.org/wiki/%E8%BE%B2%E6%9B%86\n",
        "\n",
        "  What additional challenges did you face while processing Chinese text?"
      ],
      "metadata": {
        "id": "x6hzBKLQvWmB"
      }
    }
  ]
}